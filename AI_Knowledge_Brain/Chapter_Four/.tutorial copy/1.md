在前面的学习中我们知道，相比于 AI 大模型内置的静态预训练数据，知识库中的内容能够实时更新，确保 LLM 可以访问到最新的信息，避免因信息过时或遗漏而产生的问题。 LLM 接收到用户的问题后，将首先基于关键词在知识库内检索内容。知识库将根据关键词，召回相关度排名较高的内容区块，向 LLM 提供关键上下文以辅助其生成更加精准的回答。 通过此方式确保 LLM 不仅仅依赖于训练数据中的知识，还能够处理来自实时文档和数据库的动态数据，从而提高回答的准确性和相关性。

# 1. 导入文本数据

轻点 Dify 平台顶部导航中 **"知识库"** → "**创建知识库"**。可以通过上传本地文件或导入在线数据两种方式上传文档至知识库内。

<img src="/img/1.1.png" >


### **上传本地文件**

拖拽或选中文件进行上传，**支持批量上传**。

**本地上传文档文件存在以下限制：**

* 单文档的上传大小限制为 **15MB**
* 不同 SaaS 版本的[订阅计划](https://dify.ai/pricing)限定了**批量上传个数、文档上传总数、向量存储空间**

<img src="/img/1.2.png" >

### **导入在线数据**

创建知识库时支持通过在线数据导入。知识库支持导入以下两种在线数据：


- <a href="https://docs.dify.ai/zh-hans/guides/knowledge-base/create-knowledge-and-upload-documents/import-content-data/sync-from-notion">从 Notion 导入数据</a>

- <a href="https://docs.dify.ai/zh-hans/guides/knowledge-base/create-knowledge-and-upload-documents/import-content-data/sync-from-website">从网站导入数据</a>


引用在线数据的知识库后续无法新增本地文档，也无法变更为本地文件类型的知识库，以防止单一知识库存在多种数据来源而造成管理困难。

### 后续导入

如果还没有准备好文档或其它内容数据，可以先创建一个空知识库，在后续上传本地文档或导入在线数据。

# 2. 指定分段模式

将内容上传至知识库后，接下来需要对内容进行分段与数据清洗。**该阶段是内容的预处理与数据结构化过程，长文本将会被划分为多个内容分段。**


LLM 收到用户问题后，能否精准地回答出知识库中的内容，取决于知识库对内容块的检索和召回效果。匹配与问题相关度高的文本分段对 AI 应用生成准确且全面的回应至关重要。

好比在智能客服场景下，仅需帮助 LLM 定位至工具手册的关键章节内容块即可快速得到用户问题的答案，而无需重复分析整个文档。在节省分析过程中所耗费的 Tokens 的同时，提高 AI 应用的问答质量。

### 分段模式

知识库支持两种分段模式：**通用模式**与**父子模式**。如果是首次创建知识库，建议选择父子模式。


<img src="/img/1.3.png" height=500>
<img src="/img/1.4.png" height=500>

#### 通用模式

系统按照用户自定义的规则将内容拆分为独立的分段。当用户输入问题后，系统自动分析问题中的关键词，并计算关键词与知识库中各内容分段的相关度。根据相关度排序，选取最相关的内容分段并发送给 LLM，辅助其处理与更有效地回答。

在该模式下，需要根据不同的文档格式或场景要求，参考以下设置项，手动设置文本的**分段规则**。

* **分段标识符**，默认值为 `\n`，即按照文章段落进行分块。可以遵循[正则表达式语法](https://regexr.com/)自定义分块规则，系统将在文本出现分段标识符时自动执行分段。例如  的含义是按照句子进行分段。下图是不同语法的文本分段效果：

![不同分段标识符语法的分段效果](https://assets-docs.dify.ai/2024/12/2c19c1c1a0446c00e3c07d6f4c8968e4.png)

* **分段最大长度**，指定分段内的文本字符数最大上限，超出该长度时将强制分段。默认值为 500 Tokens，分段长度的最大上限为 4000 Tokens；
* **分段重叠长度**，指的是在对数据进行分段时，段与段之间存在一定的重叠部分。这种重叠可以帮助提高信息的保留和分析的准确性，提升召回效果。建议设置为分段长度 Tokens 数的 10-25%；

**文本预处理规则，** 过滤知识库内部分无意义的内容。提供以下选项：

* 替换连续的空格、换行符和制表符
* 删除所有 URL 和电子邮件地址

配置完成后，点击"预览区块"即可查看分段后的效果。可以直观的看到每个区块的字符数。如果重新修改了分段规则，需要重新点击按钮以查看新的内容分段。


若同时批量上传了多个文档，轻点顶部的文档标题，快速切换并查看其它文档的分段效果。

<img src="/img/1.5.png" height=800>

分段规则设置完成后，接下来需指定索引方式。支持"高质量索引"和"经济索引"，详细说明请参考第三部分**设定索引方法与检索设置**。

#### **父子模式**

与**通用模式**相比，父子模式采用双层分段结构来平衡检索的精确度和上下文信息,让精准匹配与全面的上下文信息二者兼得。

其中，父区块（Parent-chunk）保持较大的文本单位（如段落），提供丰富的上下文信息；子区块（Child-chunk）则是较小的文本单位（如句子），用于精确检索。系统首先通过子区块进行精确检索以确保相关性，然后获取对应的父区块来补充上下文信息，从而在生成响应时既保证准确性又能提供完整的背景信息。可以通过设置分隔符和最大长度来自定义父子区块的分段方式。

例如在 AI 智能客服场景下，用户输入的问题将定位至解决方案文档内某个具体的句子，随后将该句子所在的段落或章节，联同发送至 LLM，补全该问题的完整背景信息，给出更加精准的回答。

其基本机制包括：

* **子分段匹配查询**：
  * 将文档拆分为较小、集中的信息单元（例如一句话），更加精准的匹配用户所输入的问题。
  * 子分段能快速提供与用户需求最相关的初步结果。
* **父分段提供上下文**：
  * 将包含匹配子分段的更大部分（如段落、章节甚至整个文档）视作父分段并提供给大语言模型（LLM）。
  * 父分段能为 LLM 提供完整的背景信息，避免遗漏重要细节，帮助 LLM 输出更贴合知识库内容的回答。

<img src="/img/1.6.png" height=500>

在该模式下，需要根据不同的文档格式或场景要求，手动分别设置父子分段的**分段规则**。

**父分段：**

父分段设置提供以下分段选项：

* **段落**

根据预设的分隔符规则和最大块长度将文本拆分为段落。每个段落视为父分段，适用于文本量较大，内容清晰且段落相对独立的文档。支持以下设置项：

* **分段标识符**，默认值为 `\n`，即按照文本段落分段。可以遵循[正则表达式语法](https://regexr.com/)自定义分块规则，系统将在文本出现分段标识符时自动执行分段。

* **分段最大长度**，指定分段内的文本字符数最大上限，超出该长度时将强制分段。默认值为 500 Tokens，分段长度的最大上限为 4000 Tokens；

* **全文**

不进行段落分段，而是直接将全文视为单一父分段。出于性能原因，仅保留文本内的前 10000 Tokens 字符，适用于文本量较小，但段落间互有关联，需要完整检索全文的场景。

<img src="/img/1.7.png">

**子分段：**

子分段文本是在父文本分段基础上，由分隔符规则切分而成，用于查找和匹配与问题关键词最相关和直接的信息。如果使用默认的子分段规则，通常呈现以下分段效果：

* 当父分段为段落时，子分段对应各个段落中的单个句子。
* 父分段为全文时，子分段对应全文中各个单独的句子。

在子分段内填写以下分段设置：

* **分段标识符**，默认值为 ，即按照句子进行分段。可以遵循[正则表达式语法](https://regexr.com/)自定义分块规则，系统将在文本出现分段标识符时自动执行分段。
* **分段最大长度**，指定分段内的文本字符数最大上限，超出该长度时将强制分段。默认值为 200 Tokens，分段长度的最大上限为 4000 Tokens；

还可以使用**文本预处理规则**过滤知识库内部分无意义的内容：

* 替换连续的空格、换行符和制表符
* 删除所有 URL 和电子邮件地址

配置完成后，点击"预览区块"即可查看分段后的效果。可以查看父分段的整体字符数。背景标蓝的字符为子分块，同时显示当前子段的字符数。

如果重新修改了分段规则，需要重新点击"预览区块"按钮以查看新的内容分段。若同时批量上传了多个文档，轻点顶部的文档标题，快速切换至其它文档并预览内容的分段效果。

>为了确保内容检索的准确性，父子分段模式仅支持使用**高质量索引**。

### 两种模式的区别是什么？

两者的主要区别在于内容区块的分段形式。**通用模式**的分段结果为多个独立的内容分段，而**父子模式**采用双层结构进行内容分段，即单个父分段的内容（文档全文或段落）内包含多个子分段内容（句子）。

不同的分段方式将影响 LLM 对于知识库内容的检索效果。在相同文档中，采用父子检索所提供的上下文信息会更全面，且在精准度方面也能保持较高水平，大大优于传统的单层通用检索方式。

<img src="/img/1.8.png" height=500>

### 如何选择分段模式？

选定分段模式后，接下来可以参考以下文档分别设定索引方式和检索方式，完成知识库的创建。

# 3. 设定索引方法与检索设置

选定内容的分段模式后，接下来设定对于结构化内容的**索引方法**与**检索设置**。

## 设定索引方法

正如搜索引擎通过高效的索引算法匹配与用户问题最相关的网页内容，索引方式是否合理将直接影响 LLM 对知识库内容的检索效率以及回答的准确性。

提供 **高质量** 与 **经济** 两种索引方法，其中分别提供不同的检索设置选项：

>**高质量：**  
在高质量模式下，使用 Embedding 嵌入模型将已分段的文本块转换为数字向量，帮助更加有效地压缩与存储大量文本信息；**使得用户问题与文本之间的匹配能够更加精准**。  
将内容块向量化并录入至数据库后，需要通过有效的检索方式调取与用户问题相匹配的内容块。高质量模式提供向量检索、全文检索和混合检索三种检索设置。选择高质量模式后，当前知识库的索引方式无法在后续降级为 **“经济”索引模式**。如需切换，建议重新创建知识库并重选索引方式。

>**经济：**  
在经济模式下，每个区块内使用 10 个关键词进行检索，降低了准确度但无需产生费用。对于检索到的区块，仅提供倒排索引方式选择最相关的区块，详细说明参照**指定检索方式**。  
若选择经济型索引方式后，若感觉实际的效果不佳，可以在知识库设置页中升级为 **“高质量”索引方式**。

## 指定检索方式

知识库在接收到用户查询问题后，按照预设的检索方式在已有的文档内查找相关内容，提取出高度相关的信息片段供语言模型生成高质量答案。这将决定 LLM 所能获取的背景信息，从而影响生成结果的准确性和可信度。

常见的检索方式包括基于向量相似度的语义检索，以及基于关键词的精准匹配：前者将文本内容块和问题查询转化为向量，通过计算向量相似度匹配更深层次的语义关联；后者通过倒排索引，即搜索引擎常用的检索方法，匹配问题与关键内容。

不同的索引方法对应差异化的检索设置。

### 高质量索引
- **向量检索：** 向量化用户输入的问题并生成查询文本的数学向量，比较查询向量与知识库内对应的文本向量间的距离，寻找相邻的分段内容。

  <img src="/img/1.9.png">

  **Rerank 模型：** 默认关闭。开启后将使用第三方 Rerank 模型再一次重排序由向量检索召回的内容分段，以优化排序结果。帮助 LLM 获取更加精确的内容，辅助其提升输出的质量。开启该选项前，需前往“设置” → “模型供应商”，提前配置 Rerank 模型的 API 秘钥。

  **TopK：** 用于筛选与用户问题相似度最高的文本片段。系统同时会根据选用模型上下文窗口大小动态调整片段数量。默认值为 3，数值越高，预期被召回的文本分段数量越多。

  **Score 阈值：** 用于设置文本片段筛选的相似度阈值，只召回超过设置分数的文本片段，默认值为 0.5。数值越高说明对于文本与问题要求的相似度越高，预期被召回的文本数量也越少。

  > TopK 和 Score 设置仅在 Rerank 步骤生效，因此需要添加并开启 Rerank 模型才能应用两者中的设置参数。

- **全文检索：** 关键词检索，即索引文档中的所有词汇。用户输入问题后，通过明文关键词匹配知识库内对应的文本片段，返回符合关键词的文本片段；类似搜索引擎中的明文检索。

  <img src="/img/1.10.png">

- **混合检索：** 同时执行全文检索和向量检索，或 Rerank 模型，从查询结果中选择匹配用户问题的最佳结果。

  <img src="/img/1.11.png">

  在混合检索设置内可以选择启用 **“权重设置”** 或 **“Rerank 模型”**。

    * **权重设置**

      允许用户赋予语义优先和关键词优先自定义的权重。关键词检索指的是在知识库内进行全文检索（Full Text Search），语义检索指的是在知识库内进行向量检索（Vector Search）。

      * **将语义值拉至 1**

        **仅启用语义检索模式**。借助 Embedding 模型，即便知识库中没有出现查询中的确切词汇，也能通过计算向量距离的方式提高搜索的深度，返回正确内容。此外，当需要处理多语言内容时，语义检索能够捕捉不同语言之间的意义转换，提供更加准确的跨语言搜索结果。
      * **将关键词的值拉至 1**

        **仅启用关键词检索模式**。通过用户输入的信息文本在知识库全文匹配，适用于用户知道确切的信息或术语的场景。该方法所消耗的计算资源较低，适合在大量文档的知识库内快速检索。
      * **自定义关键词和语义权重**

        除了将不同的数值拉至 1，还可以不断调试二者的权重，找到符合业务场景的最佳权重比例。

    > 语义检索指的是比对用户问题与知识库内容中的向量距离。距离越近，匹配的概率越大。
### 经济索引

- **倒排索引：** 在经济索引方式下，仅提供**倒排索引方式**。这是一种用于快速检索文档中关键词的索引结构，常用于在线搜索引擎。倒排索引仅支持 **TopK** 设置项。
  
  <img src="/img/1.12.png">

## 4. 保存知识库

这里分段设置为**父子分段**，索引方式设置为**高质量**，检索方式设置为**混合检索**，TopK 设置为 5，Score 阈值设置为 0.5，Rerank 模型设置为关闭。

<img src="/img/1.13.png" height=500>





