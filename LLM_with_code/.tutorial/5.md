StarCoder模型是一种用于代码的大规模语言模型，可以执行各种任务，如代码补全、代码修改、代码解释和技术支持。

它是在GitHub的许可数据（包括80多种编程语言、Git提交、GitHub问题和Jupyter notebook）上进行训练的。它的语境长度超过8,000个词元，这使它能比其他任何开源语言模型处理更多的输入。此外，它还改进了许可，简化了公司将该模型集成到其产品中的流程。

StarCoder模型已在多个基准测试中进行过评估，测试了其在不同语言和领域中编写和理解代码的能力，包括在上述的HumanEval和MBPP中其得分分别为33.6%和52.7%。

此外，它还参加了MultiPL- E(该模型在许多语言上与OpenAI所用的code- cushman- 001型不相上下，甚至更胜一筹)、DS- 1000(该模型明显优于code- cushman- 001模型以及所有其他开放存取模型)和Tech Assistant Prompt(该模型能够以相关的准确信息回答各种询问)的测试。根据HuggingFace于2023年5月4日发布的一项调查,以HumanEval和MBPP为基准,与其他模型相比,StarCoder表现出了其具有强大的能力，这项研究的结果如下表所示：

|Model 	|HumanEval 	|MBPP|
|:-:|:-:|:-:|
|LLaMA-7B 	|10.5 	|17.7|
|LaMDA-137B 	|14.0 	|14.8|
|LLaMA-13B 	|15.8 	|22.0|
|CodeGen-16B-Multi 	|18.3 	|20.9|
|LLaMA-33B 	|21.7 	|30.2|
|CodeGeeX 	|22.9 	|24.4|
|LLaMA-65B 	|23.7 	|37.7|
|PaLM-540B 	|26.2 	|36.8|
|CodeGen-16B-Mono 	|29.3 	|35.3|
|StarCoderBase 	|30.4 	|49.0|
|code-cushman-001 	|33.5 	|45.9|
|**StarCoder** 	|**33.6** 	|**52.7**|
|StarCoder-Prompted 	|40.8 	|49.5|
  
各类大规模语言模型的评估基准结果(来源:https://huggingface.co/blog/starcoder)


## 启用StarCoder

### 利用HuggingFace远程使用StarCoder

利用LangChain中的HuggingFaceHub封装器(需在.env文件中设置HuggingFaceAPI):
```python
import os 
from dotenv import load_dotenv 

load_dotenv() 

hugging_face_api = os.environ["HUGGINGFACEHUB_API_TOKEN"]
```

为StarCoder模型设置repo_id并初始化它:
```python
from langchain import HuggingFaceHub 
from langchain import PromptTemplate,LLMChain 

repo_id = "bigcode/starcoderplus" 
llm = HuggingFaceHub(
    repo_id = repo_id,model_kwargs = {"temperature":0.2,"max_new_tokens": 500} 
) 
```

>**注意：**  
StarCoder是HuggingFace Hub 上使用的门控模型,这意味着需要直接从 bigcode/starcoderplus 仓库请求访问,然后才能连接到它。

### 利用ollama本地使用StarCoder
使用Python的requests库与Ollama的REST API交互：
```python
import requests
import json

def llm(prompt: str, model="starcoder2:7b") -> str:
    """调用StartCoder模型生成回答"""
    endpoint = "http://localhost:11434/api/generate"
    payload = {
        "model": model,
        "prompt": prompt,
        "stream": False,  # 关闭流式输出获取完整响应
        "options": {
            "temperature": 0.2,
            "num_predict": 500
        }
    }
    
    try:
        response = requests.post(
            url=endpoint,
            data=json.dumps(payload),
            headers={"Content-Type":"application/json"},
            timeout=120  # 增加超时时间
        )
        response.raise_for_status()
        return response.json()["response"]
    
    except requests.exceptions.RequestException as e:
        print(f"API请求失败: {e}")
        return ""
```
## 使用StarCoder

现在已经设置完毕,接下来要求模型编译一些代码。
### 生成第  $n$  个斐波那契数字

提示词如下:

```python
prompt = """
How can I write a Python function to generate the nth Fibonacci number. Give me an example and explain it.
"""
print(llm(prompt))
```

> **回顾一下：**  
斐波那契数列是一个以0和1开头的数学数列,其中后面的每个数字都是前面两个数字的和。例如, 斐波那契数列的前10个数字是0、1、1、2、3、5、8、13、21和34。  
计算第  $n$  个斐波那契数字(用  $F(n)$  表示)有不同的方法。一种方法是使用递推公式:  
$$
F(n) = F(n - 1) + F(n - 2)
$$
  
>这意味着要找到  $F(n)$  ,需要先找到  $F(n - 1)$  和  $F(n - 2)$  ,然后将它们相加。如果  $n$  等于0或1,只需返回  $n$  作为答案。

然后会看到下面的输出结果,如图9.5所示。

<p align="center">
<img src="/img/5.1.png" width="600">
</p>



如上所示，在解释函数的同时，它还提出了解决问题的不同方法。

### 与计算机玩井字游戏
现在，要求该模型生成一个网页，与计算机玩井字游戏：
```python
prompt = """ 
Generate the html code for a single page website that let the user play tic tac toe.
"""
print(llm(prompt))
```
下面是相应的输出结果：


```bash
# TicTacToe

This is a simple web application that allows you to play tic tac toe against another player. The game can be played in two ways:

1. You can play against the computer and see how well you do at it.
2. You can play against another person on your local network.

## Running the Game

To run this game, first clone the repository to your local machine using the following command:

    git clone https://github.com/joshua-gordon/TicTacToe.git

Then navigate into the directory and start a web server in that directory with the following command:

    python -m SimpleHTTPServer 8000

Now you can open your browser to `http://localhost:8000` and play!
```


有趣的是，在这种情况下，模型并没有生成整段代码，而是给出了用于克隆和运行一个git仓库的指令，以实现这一结果。


代码理解和生成是大规模语言模型具有的强大功能。除了这些能力, 还可以考虑其在代码生成之外的更多应用。事实上, 代码还可以被视为一种后台推理工具, 用于提出复杂问题的解决方案, 例如能源优化问题, 而不是算法任务。为此, 可以利用 LangChain 创建功能强大的智能体, 让它们像算法一样行动。接下来的章节将讲解如何做到这一点。