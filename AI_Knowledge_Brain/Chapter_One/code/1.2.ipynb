{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "latex"
    }
   },
   "source": [
    "## PDF文档处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始文本:第1页  \n",
      "合同编号： XYZ-2025 \n",
      "甲方：ABC公司... \n",
      " \n",
      "  第2页 1.1条款... \n",
      "处理后:合同编号： XYZ-2025 甲方：ABC公司... 1.1条款...\n"
     ]
    }
   ],
   "source": [
    "import PyPDF2\n",
    "import re\n",
    "\n",
    "def extract_pdf_text(pdf_path):\n",
    "    \"\"\"提取PDF文本内容\"\"\"\n",
    "    text = \"\"\n",
    "    with open(pdf_path, \"rb\") as file:\n",
    "        reader = PyPDF2.PdfReader(file)\n",
    "        for page in reader.pages:\n",
    "            page_text = page.extract_text()\n",
    "            if page_text:\n",
    "                text += page_text\n",
    "    return text\n",
    "\n",
    "def clean_pdf_text(text):\n",
    "    \"\"\"清洗PDF文本\"\"\"\n",
    "    # 移除页眉页脚\n",
    "    cleaned_text = re.sub(r\"第\\s*\\d+\\s*页\", \"\", text)\n",
    "    # 压缩空白字符\n",
    "    cleaned_text = re.sub(r\"\\s+\", \" \", cleaned_text).strip()\n",
    "    return cleaned_text\n",
    "\n",
    "# 使用示例\n",
    "pdf_path = \"./document.pdf\"\n",
    "raw_text = extract_pdf_text(pdf_path)\n",
    "print(\"原始文本:\"+ raw_text)\n",
    "print(\"处理后:\" + clean_pdf_text(raw_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TXT文档处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始文本:# 第一部分：UTF-8 编码内容（中文+英文+空格）\n",
      "这是一段正常的中文文本。  \n",
      "Hello, World!  \n",
      "这里包含一些空行：  \n",
      "\n",
      "\n",
      "（此处有多个空行）  \n",
      "接下来是特殊符号测试：@#$%^&*()_+  \n",
      "\n",
      "# 第二部分：GBK 编码内容（可能出现乱码，需用 GBK 解码）  \n",
      "如果用 UTF-8 打开这段文字，可能会显示乱码：  \n",
      "比如：你好，世界！  \n",
      "但用 GBK 编码保存时，这些中文会正确显示。  \n",
      "\n",
      "# 第三部分：Latin-1 编码内容（英文为主）  \n",
      "Latin-1 encoding test: ñ, ü, é  \n",
      "This is a line with Latin characters.\n",
      "处理后: 第一部分UTF8 编码内容中文英文空格 这是一段正常的中文文本 Hello World 这里包含一些空行 此处有多个空行 接下来是特殊符号测试_  第二部分GBK 编码内容可能出现乱码需用 GBK 解码 如果用 UTF8 打开这段文字可能会显示乱码 比如你好世界 但用 GBK 编码保存时这些中文会正确显示  第三部分Latin1 编码内容英文为主 Latin1 encoding test ñ ü é This is a line with Latin characters\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def read_txt_with_encoding(txt_path):\n",
    "    \"\"\"多编码尝试读取TXT文件\"\"\"\n",
    "    encodings = [\"utf-8\", \"gbk\", \"latin-1\"]\n",
    "    for enc in encodings:\n",
    "        try:\n",
    "            with open(txt_path, \"r\", encoding=enc) as f:\n",
    "                return f.read()\n",
    "        except UnicodeDecodeError:\n",
    "            continue\n",
    "    raise ValueError(\"无法识别编码\")\n",
    "\n",
    "def clean_txt_text(text):\n",
    "    \"\"\"清洗文本内容\"\"\"\n",
    "    # 移除空行\n",
    "    lines = [line.strip() for line in text.split(\"\\n\") if line.strip()]\n",
    "    cleaned_text = \" \".join(lines)\n",
    "    # 过滤特殊字符\n",
    "    cleaned_text = re.sub(r\"[^\\w\\s\\u4e00-\\u9fa5]\", \"\", cleaned_text)\n",
    "    return cleaned_text\n",
    "\n",
    "# 使用示例\n",
    "txt_path = \"./data.txt\"\n",
    "raw_text = read_txt_with_encoding(txt_path)\n",
    "print(\"原始文本:\" + raw_text)\n",
    "print(\"处理后:\" +  clean_txt_text(raw_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word文档处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'type': 'text', 'content': '项目总结报告'}, {'type': 'text', 'content': '本项目自2023年1月启动...'}, {'type': 'text', 'content': '成果展示'}]\n"
     ]
    }
   ],
   "source": [
    "from docx import Document\n",
    "\n",
    "def extract_word_content(word_path):\n",
    "    \"\"\"提取Word结构化内容\"\"\"\n",
    "    doc = Document(word_path)\n",
    "    content_list = []\n",
    "  \n",
    "    for para in doc.paragraphs:\n",
    "        para_text = para.text.strip()\n",
    "        if not para_text:\n",
    "            continue\n",
    "          \n",
    "        style_name = para.style.name\n",
    "        if style_name.startswith(\"Heading\"):\n",
    "            # 标题处理\n",
    "            content_list.append({\n",
    "                \"type\": \"heading\",\n",
    "                \"level\": int(style_name[-1]),\n",
    "                \"content\": para_text\n",
    "            })\n",
    "        else:\n",
    "            # 正文处理\n",
    "            content_list.append({\n",
    "                \"type\": \"text\",\n",
    "                \"content\": para_text\n",
    "            })\n",
    "  \n",
    "    return content_list\n",
    "\n",
    "# 使用示例\n",
    "word_path = \"./report.docx\"\n",
    "content = extract_word_content(word_path)\n",
    "print(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Markdown文档处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正则清洗:\n",
      "第一章 入门 **Markdown 是轻量级标记语言**，常用于写文档。\n",
      "HTML转换:\n",
      "第一章 入门 Markdown 是轻量级标记语言 ，常用于写文档。 python  \n",
      "print(\"Hello, Markdown!\")\n",
      "保留层级结构:\n",
      "第一章 入门\n",
      "**Markdown 是轻量级标记语言**，常用于写文档。\n",
      "```python\n",
      "print(\"Hello, Markdown!\")\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import markdown2\n",
    "\n",
    "def md_to_clean_text(md_content):\n",
    "    \"\"\"正则清洗Markdown\"\"\"\n",
    "    # 清除标题标记\n",
    "    text = re.sub(r'^#+\\s', '', md_content, flags=re.MULTILINE)\n",
    "    # 清除列表标记\n",
    "    text = re.sub(r'^\\s*[-*0-9.]+\\s', '', text, flags=re.MULTILINE)\n",
    "    # 清除链接\n",
    "    text = re.sub(r'\\[.*?\\]\\(.*?\\)', '', text)\n",
    "    # 清除代码块\n",
    "    text = re.sub(r'```[\\s\\S]*?```', '', text)\n",
    "    # 合并空格\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "\n",
    "def md_to_html_text(md_content):\n",
    "    \"\"\"通过HTML转换处理Markdown\"\"\"\n",
    "    html = markdown2.markdown(md_content)\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    return soup.get_text(separator=' ', strip=True)\n",
    "\n",
    "def md_keep_structure(md_content):\n",
    "    \"\"\"保留Markdown层级结构\"\"\"\n",
    "    lines = md_content.split('\\n')\n",
    "    result = []\n",
    "  \n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        if line.startswith('#'):\n",
    "            level = line.count('#')\n",
    "            title = line.lstrip('#').strip()\n",
    "            result.append(f\"{'  '*(level-1)}{title}\")\n",
    "        elif line:\n",
    "            result.append(line)\n",
    "  \n",
    "    return '\\n'.join(result)\n",
    "\n",
    "# 测试\n",
    "if __name__ == \"__main__\":\n",
    "    md_path = \"./test.md\"\n",
    "    with open(md_path, 'r', encoding='utf-8') as f:\n",
    "        md_content = f.read()\n",
    "    print(\"正则清洗:\\n\" + md_to_clean_text(md_content))\n",
    "    print(\"HTML转换:\\n\" + md_to_html_text(md_content))\n",
    "    print(\"保留层级结构:\\n\" + md_keep_structure(md_content))\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
