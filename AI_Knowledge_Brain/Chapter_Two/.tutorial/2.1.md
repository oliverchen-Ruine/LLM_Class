## 1.为什么不能直接使用文字？

前面我们对文本进行了分块预处理，得到了一个**分词列表**。但是，直接使用分词列表作为文本向量，会存在以下问题：

- **二进制表达效率问题**：计算机底层使用二进制（0和1）存储所有数据，文字字符通过编码（如ASCII、Unicode）被转换为二进制序列，直接存储原始文字会导致每个字符需要固定长度的二进制位并且相同含义的词汇可能有多种文本表达（如"电脑"和"计算机"），但其二进制编码完全不同
- **文本处理**：每段文本都无法统一处理（长度不同，语义复杂）
- **不能计算“相似度”**：无法判断两个文本是否描述同一件事
- **向量是数学概念**：向量是数学概念，可以方便地使用数学工具进行计算
- **文本的数字指纹指纹**：可以方便地计算两个向量的相似度


## 2.如何数字表达
假如用数字来描述一只猫，需要从以下几个维度考虑：
- 重量（比如5kg）
- 身高（比如30cm）
- 毛色（白色记作1，黑色记作2……）
- ...

最终你得到一个数字列表：[5, 30, 1,...]，这就是一个**多维向量**。我们在AI中做的就是类似的事情：用几百、几千维的数字列表来“描述一段文本的语义”。


## 3.文本向量举例
比如我们有两个句子：
- “我想看喜剧片”
- “有没有好笑的电影推荐？”

虽然这两句话用词不同，但在理解上它们相似。使用向量表示后，它们就会变成两个**非常接近**的向量，如下：

```
句子A向量：[0.12, 0.98, ..., 0.56]   ←→
句子B向量：[0.13, 0.97, ..., 0.55]   ←→ 非常相近
```

计算机就可以据此判断它们“语义相似”。

<img src="/img/2.1.1.png">

## 4.如何计算向量相似度
最常用NLP 度量算法：
1. 点积： 𝑎∗𝑏=|𝑎||𝑏|cos𝜃，输出任意大小的值
2. 余弦距离： 𝑐𝑜𝑠𝑖𝑛es=(𝐴·𝐵)/(||𝐴|| ||𝐵||) ，产生一个标准化值（-1 和 1 之间）
<p align="center">
<img src="/img/2.1.2.png">
<br>点积(左)和余弦距离(右)的对比</br>
</p>


## 5.向量数据库

>核心价值:通过向量化，可以将语义维度压缩，原始文字以线性二进制序列存储时，"苹果手机"和"iPhone"的二进制编码毫无关联性，而向量化后可通过向量距离（如余弦相似度）量化语义关联。**但是**如果有几千条或几百万条文本数据，手动比对不现实，这时就需要向量数据库登场。

| 能力 | 传统数据库 | 向量数据库 |
|------|------------|------------|
| 语义匹配 | ❌ 关键词匹配 | ✅ 语义理解 |
| 非结构化处理 | ❌ 仅结构化数据 | ✅ 文本/图像等 |
| 相似度检索 | ❌ 线性扫描 | ✅ 近邻算法 |

### 5.1 与传统数据库区别

例如：搜索“猫咪”，得到“猫咪”关键字结果，而无法得到“银渐层”“布偶”

```JAVA
SELECT * FROM table WHERE name = "猫咪"
```

问题：传统数据库无法识别语义关系，需要打上标签进行关联，才能实现语义搜索
```JAVA
SELECT * FROM table WHERE name = "猫咪" AND feature = "银渐*"
```

### 5.2 核心功能

* 高维向量的存储与索引（Indexing）
* 相似度检索（k-NN、Approximate k-NN）
* 多字段过滤（metadata filter）
* 批量插入与更新

### 5.3 常见的向量数据库产品

| 数据库名称    | 特点             | 是否开源 | 备注                     |
| -------- | -------------- | ---- | ---------------------- |
| FAISS    | 速度快、适合本地部署     | 是    | Facebook 出品，适合中小型向量集合  |
| Milvus   | 分布式、高性能、支持 GPU | 是    | Zilliz 出品，适用于大规模数据     |
| Weaviate | 内置语义搜索、支持多语言模型 | 是    | 提供多种客户端 SDK            |
| Qdrant   | 高性能、易集成、支持过滤查询 | 是    | 开发者社区活跃，支持 Docker 快速部署 |
| Pinecone | 商业化产品、托管部署     | 否    | 简单易用，适合 SaaS 应用        |
