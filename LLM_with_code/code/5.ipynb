{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Using a LocalBox which is not fully isolated\n",
      "      and not scalable across multiple users.\n",
      "      Make sure to use a CODEBOX_API_KEY in production.\n",
      "      Set envar SHOW_INFO=False to not see this again.\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Please set the API key for the LLM you want to use.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      3\u001b[39m os.environ[\u001b[33m'\u001b[39m\u001b[33mOPENAI_API_KEY\u001b[39m\u001b[33m'\u001b[39m] = \u001b[33m\"\u001b[39m\u001b[33msk-YIN03tURjRYmhcmv0yIT3BlbkFjv0aj9MwaCcmmjNpVnCo\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      5\u001b[39m os.environ[\u001b[33m'\u001b[39m\u001b[33mVERBOSE\u001b[39m\u001b[33m'\u001b[39m] = \u001b[33m\"\u001b[39m\u001b[33mTrue\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mCodeInterpreterSession\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[32m      8\u001b[39m     \u001b[38;5;66;03m# 定义用户请求 \u001b[39;00m\n\u001b[32m      9\u001b[39m     user_request = \u001b[33m\"\u001b[39m\u001b[33mAnalyze this dataset and plot something interesting about it.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     10\u001b[39m     files = [ File.from_path(\u001b[33m\"\u001b[39m\u001b[33mdrive/MyDrive/titanic.csv\u001b[39m\u001b[33m\"\u001b[39m), ]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.1/lib/python3.11/site-packages/codeinterpreterapi/session.py:70\u001b[39m, in \u001b[36mCodeInterpreterSession.__init__\u001b[39m\u001b[34m(self, llm, additional_tools, callbacks, **kwargs)\u001b[39m\n\u001b[32m     68\u001b[39m \u001b[38;5;28mself\u001b[39m.verbose = kwargs.get(\u001b[33m\"\u001b[39m\u001b[33mverbose\u001b[39m\u001b[33m\"\u001b[39m, settings.DEBUG)\n\u001b[32m     69\u001b[39m \u001b[38;5;28mself\u001b[39m.tools: \u001b[38;5;28mlist\u001b[39m[BaseTool] = \u001b[38;5;28mself\u001b[39m._tools(additional_tools)\n\u001b[32m---> \u001b[39m\u001b[32m70\u001b[39m \u001b[38;5;28mself\u001b[39m.llm: BaseLanguageModel = llm \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_choose_llm\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     71\u001b[39m \u001b[38;5;28mself\u001b[39m.callbacks = callbacks\n\u001b[32m     72\u001b[39m \u001b[38;5;28mself\u001b[39m.agent_executor: Optional[AgentExecutor] = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.1/lib/python3.11/site-packages/codeinterpreterapi/session.py:167\u001b[39m, in \u001b[36mCodeInterpreterSession._choose_llm\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    161\u001b[39m     \u001b[38;5;28mself\u001b[39m.log(\u001b[33m\"\u001b[39m\u001b[33mUsing Chat Anthropic\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    162\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ChatAnthropic(\n\u001b[32m    163\u001b[39m         model_name=settings.MODEL,\n\u001b[32m    164\u001b[39m         temperature=settings.TEMPERATURE,\n\u001b[32m    165\u001b[39m         anthropic_api_key=settings.ANTHROPIC_API_KEY,\n\u001b[32m    166\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m167\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mPlease set the API key for the LLM you want to use.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mValueError\u001b[39m: Please set the API key for the LLM you want to use."
     ]
    }
   ],
   "source": [
    "from codeinterpreterapi import CodeInterpreterSession,File\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = \"sk-YIN03tURjRYmhcmv0yIT3BlbkFjv0aj9MwaCcmmjNpVnCo\"\n",
    "\n",
    "os.environ['VERBOSE'] = \"True\"\n",
    "\n",
    "async with CodeInterpreterSession() as session:\n",
    "    # 定义用户请求 \n",
    "    user_request = \"Analyze this dataset and plot something interesting about it.\"\n",
    "    files = [ File.from_path(\"drive/MyDrive/titanic.csv\"), ]\n",
    "    # 生成响应\n",
    "    response = await session.generate_response(user_request, files=files)\n",
    "    # 输出给用户\n",
    "    print(\"AI:\", response.content)\n",
    "    for file in response.files:\n",
    "        file.show_image()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
